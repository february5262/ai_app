# Machine Learning in IOS

## CoreML

### Inception V3

1. coreMLì—ì„œ ë‹¤ìš´ë°›ì•„ì„œ {í”„ë¡œì íŠ¸}ì— ì¶”ê°€í•´ì¤€ë‹¤
2. project ì¶”ê°€ì‹œ ì…‹íŒ… 
    
    ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-03-31 á„‹á…©á„’á…® 5.16.06.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/3a9c7cf3-8954-4f4c-9411-01e0997a8842/850d3ece-1d85-44cc-b22a-12d6194d11e6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2024-03-31_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.16.06.png)
    
    - Create groups
        - finderì—ì„œ ì ‘ê·¼í•´ì„œ íŒŒì¼ì„ ì¶”ê°€í•´ë„ projectì—ëŠ” ë°˜ì˜ë˜ì§€ ì•ŠëŠ”ë‹¤
        - ì´ ê²½ìš° ê·¸ë£¹ì˜ ê° íŒŒì¼ì´ ì†í•´ì•¼ í•  íƒ€ê²Ÿì„ ì„ íƒí•  ìˆ˜ ìˆë‹¤.
    - Create folder reference
        - finderì—ì„œ ì ‘ê·¼í•´ íŒŒì¼ì„ ì¶”ê°€/ì œê±°í•˜ë©´ projectì— ì¦‰ì‹œ ë°˜ì˜ëœë‹¤ : í´ë”ì™€ 1:1 ë§¤ì¹­
        - ë³„ë„ì˜ íŒŒì¼ì´ ì•„ë‹Œ, ì „ì²´ í´ë”ì— ëŒ€í•´ì„œ íƒ€ê²Ÿì„ ì§€ì •í•  ìˆ˜ ìˆë‹¤.
    
    ** ëŒ€ë¶€ë¶„ create groups ì‚¬ìš©
    

## Vision

# Object Detection

```swift
  func detectedObject() {
        if let ciImage = self.selectedCIImage {
            do {
                let vnCoreMLModel = try VNCoreMLModel(for: Inceptionv3(configuration: .init()).model)
                let request = VNCoreMLRequest(model: vnCoreMLModel, completionHandler: self.handleObjectDetection)
                request.imageCropAndScaleOption = .centerCrop
                let requestHandler = VNImageRequestHandler(ciImage: ciImage, options: [:])
                try requestHandler.perform([request])
                
            } catch {
                print(error)
            }
        }
    }
    
    func handleObjectDetection(request: VNRequest, error: Error?) {
        if let result = request.results?.first as? VNClassificationObservation {
            self.categoryLabel.text = result.identifier
            self.confidenceLabel.text = "\(String(format:"%.1f",result.confidence * 100))%" // confidence:Float , .1f = ì†Œìˆ˜ì  í•œìë¦¬ë§Œ í‘œí˜„
        }
    }
```

[RPReplay_Final1712017832.MP4](https://prod-files-secure.s3.us-west-2.amazonaws.com/3a9c7cf3-8954-4f4c-9411-01e0997a8842/a89cf3df-dcd3-49ff-94af-a1997ede37e9/RPReplay_Final1712017832.mp4)

[RPReplay_Final1711889008.MP4](https://prod-files-secure.s3.us-west-2.amazonaws.com/3a9c7cf3-8954-4f4c-9411-01e0997a8842/faf8ee18-55ad-45f4-9d31-e990f68d559e/RPReplay_Final1711889008.mp4)

# Multi-threading

<aside>
ğŸ’¡ UI ê´€ë ¨ ì½”ë“œëŠ” ë¬´ì¡°ê±´ main thread ì—ì„œ

</aside>

```swift
DispatchQueue.global(qos: .userInitiated).async { // ML ì½”ë“œë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
                self.detectedObject()
            }
            
...

func handleObjectDetection(request: VNRequest, error: Error?) {
        if let result = request.results?.first as? VNClassificationObservation {
        
        // í•˜ë‹¨ ì½”ë“œëŠ” UI ê´€ë ¨ ì½”ë“œì´ê¸° ë•Œë¬¸ì— ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•´ì¤˜ì•¼í•¨
        // self.categoryLabel.text = result.identifier
        // self.confidenceLabel.text = "\(String(format:"%.1f",result.confidence * 100))%" // confidence:Float , .1f = ì†Œìˆ˜ì  í•œìë¦¬ë§Œ í‘œí˜„
         
         DispatchQueue.main.async {
                self.categoryLabel.text = result.identifier
                self.confidenceLabel.text = "\(String(format:"%.1f",result.confidence * 100))%" // confidence:Float , .1f = ì†Œìˆ˜ì  í•œìë¦¬ë§Œ í‘œí˜„
          }
        
        }
    }
```

# Face Analysis

### UIView

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-04-07 á„‹á…©á„’á…® 5.49.32.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/3a9c7cf3-8954-4f4c-9411-01e0997a8842/2f58389c-f01e-493a-aea2-22418c05b463/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2024-04-07_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.49.32.png)

ddd

```swift
func displayUI(for faces:[VNFaceObservation]){
        if let faceImage = self.selectedImage {
        //imageRect : image size
            let imageRect = AVMakeRect(aspectRatio: faceImage.size, insideRect: self.selectedImageView.bounds)
            
            for face in faces {
                let w = face.boundingBox.size.width * imageRect.width
                let h = face.boundingBox.size.height * imageRect.height
                let x = face.boundingBox.origin.x * imageRect.width
                let y = imageRect.maxY - (face.boundingBox.origin.y * imageRect.height)
                
                let layer = CAShapeLayer() // ImageView ì•ˆì— ì‚¬ê°í˜• ê·¸ë¦¬ëŠ” layer 
                layer.frame = CGRect(x: x, y: y, width: w, height: h)
                layer.borderColor = UIColor.red.cgColor
                layer.borderWidth = 1
                self.selectedImageView.layer.addSublayer(layer)
            }
        }
    }
```
